/bin/bash /home/jinyao/PycharmProjects/IADBE/train_test_btech_csflow.sh
(IADBE) jinyao@jinyao-System-Product-Name:~/PycharmProjects/IADBE$ /bin/bash /home/jinyao/PycharmProjects/IADBE/train_test_btech_csflow.sh
Running command: anomalib train --data anomalib.data.BTech --data.category 01 --config ./configs/models/csflow.yaml
2024-06-25 15:49:45,942 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/25/24 15:49:45] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-25 15:49:45,958 - anomalib.models.components.base.anomaly_module - INFO - Initializing Csflow model.
                    INFO     Initializing Csflow model.                                                                                                                                                anomaly_module.py:42
2024-06-25 15:49:45,964 - anomalib.callbacks - INFO - Loading the callbacks
                    INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-25 15:49:45,965 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 1 for Csflow
                    INFO     Overriding gradient_clip_val from None with 1 for Csflow                                                                                                                          engine.py:84
2024-06-25 15:49:45,966 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Csflow
                    INFO     Overriding num_sanity_val_steps from None with 0 for Csflow                                                                                                                       engine.py:84
2024-06-25 15:49:46,043 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/25/24 15:49:46] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-25 15:49:46,051 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-25 15:49:46,052 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-25 15:49:46,052 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-25 15:49:46,053 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-25 15:49:46,054 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
[06/25/24 15:49:46] WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-25 15:49:46,055 - anomalib.data.image.btech - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                btech.py:351
2024-06-25 15:49:46,093 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-06-25 15:49:48,437 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/25/24 15:49:48] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ loss                  │ CsFlowLoss               │      0 │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
│ 7 │ model                 │ CsFlowModel              │  292 M │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 275 M
Non-trainable params: 17.5 M
Total params: 292 M
Total estimated model params size (MB): 1.2 K
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/module.py:494: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing
`Trainer(logger=ALogger(...))`
Epoch 3/239 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:09 • 0:00:00 2.76it/s train_loss_step: 16.449 pixel_AUROC: 0.500 pixel_PRO: 0.964 train_loss_epoch: 18.3462024-06-25 15:51:14,395 - anomalib.callbacks.timer - INFO - Training took 85.94 seconds
[06/25/24 15:51:14] INFO     Training took 85.94 seconds                                                                                                                                                        timer.py:59
Epoch 3/239 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:09 • 0:00:00 2.76it/s train_loss_step: 16.449 pixel_AUROC: 0.500 pixel_PRO: 0.957 train_loss_epoch: 17.801
2024-06-25 15:51:14,403 - anomalib.data.image.btech - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                btech.py:351
2024-06-25 15:51:14,692 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/25/24 15:51:14] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:13 • 0:00:00 0.15it/s  2024-06-25 15:51:34,298 - anomalib.callbacks.timer - INFO - Testing took 18.742379426956177 seconds
Throughput (batch_size=32) : 3.7348512910437983 FPS
[06/25/24 15:51:34] INFO     Testing took 18.742379426956177 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 3.7348512910437983 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.25121477246284485    │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.4761073589324951     │
│         pixel_PRO         │     0.956647515296936     │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:13 • 0:00:00 0.15it/s
Running command: anomalib train --data anomalib.data.BTech --data.category 02 --config ./configs/models/csflow.yaml
2024-06-25 15:51:42,480 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/25/24 15:51:42] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-25 15:51:42,496 - anomalib.models.components.base.anomaly_module - INFO - Initializing Csflow model.
                    INFO     Initializing Csflow model.                                                                                                                                                anomaly_module.py:42
2024-06-25 15:51:42,502 - anomalib.callbacks - INFO - Loading the callbacks
                    INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-25 15:51:42,503 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 1 for Csflow
                    INFO     Overriding gradient_clip_val from None with 1 for Csflow                                                                                                                          engine.py:84
2024-06-25 15:51:42,504 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Csflow
                    INFO     Overriding num_sanity_val_steps from None with 0 for Csflow                                                                                                                       engine.py:84
2024-06-25 15:51:42,582 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/25/24 15:51:42] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-25 15:51:42,590 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-25 15:51:42,591 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-25 15:51:42,591 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-25 15:51:42,592 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-25 15:51:42,593 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-25 15:51:42,602 - anomalib.data.image.btech - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                btech.py:351
2024-06-25 15:51:42,622 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-06-25 15:51:44,998 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/25/24 15:51:44] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ loss                  │ CsFlowLoss               │      0 │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
│ 7 │ model                 │ CsFlowModel              │  292 M │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 275 M
Non-trainable params: 17.5 M
Total params: 292 M
Total estimated model params size (MB): 1.2 K
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/module.py:494: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing
`Trainer(logger=ALogger(...))`
Epoch 3/239 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:05 • 0:00:00 2.89it/s train_loss_step: 15.667 pixel_AUROC: 0.500 pixel_PRO: 0.400 train_loss_epoch: 17.1382024-06-25 15:52:53,300 - anomalib.callbacks.timer - INFO - Training took 68.28 seconds
[06/25/24 15:52:53] INFO     Training took 68.28 seconds                                                                                                                                                        timer.py:59
Epoch 3/239 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:05 • 0:00:00 2.89it/s train_loss_step: 15.667 pixel_AUROC: 0.500 pixel_PRO: 0.341 train_loss_epoch: 16.705
2024-06-25 15:52:53,304 - anomalib.data.image.btech - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                btech.py:351
2024-06-25 15:52:53,567 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/25/24 15:52:53] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:31 • 0:00:00 0.23it/s  2024-06-25 15:53:29,610 - anomalib.callbacks.timer - INFO - Testing took 35.027804374694824 seconds
Throughput (batch_size=32) : 6.5662123020807766 FPS
[06/25/24 15:53:29] INFO     Testing took 35.027804374694824 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 6.5662123020807766 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.7309999465942383     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.6890621781349182     │
│         pixel_PRO         │    0.34057092666625977    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:31 • 0:00:00 0.23it/s
Running command: anomalib train --data anomalib.data.BTech --data.category 03 --config ./configs/models/csflow.yaml
2024-06-25 15:53:37,940 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/25/24 15:53:37] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-25 15:53:37,956 - anomalib.models.components.base.anomaly_module - INFO - Initializing Csflow model.
                    INFO     Initializing Csflow model.                                                                                                                                                anomaly_module.py:42
2024-06-25 15:53:37,961 - anomalib.callbacks - INFO - Loading the callbacks
                    INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-25 15:53:37,962 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 1 for Csflow
                    INFO     Overriding gradient_clip_val from None with 1 for Csflow                                                                                                                          engine.py:84
2024-06-25 15:53:37,963 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Csflow
                    INFO     Overriding num_sanity_val_steps from None with 0 for Csflow                                                                                                                       engine.py:84
2024-06-25 15:53:38,040 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/25/24 15:53:38] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-25 15:53:38,048 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-25 15:53:38,049 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-25 15:53:38,049 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-25 15:53:38,050 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-25 15:53:38,051 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
[06/25/24 15:53:38] WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-25 15:53:38,052 - anomalib.data.image.btech - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                btech.py:351
2024-06-25 15:53:38,072 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-06-25 15:53:40,410 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/25/24 15:53:40] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ loss                  │ CsFlowLoss               │      0 │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
│ 7 │ model                 │ CsFlowModel              │  292 M │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 275 M
Non-trainable params: 17.5 M
Total params: 292 M
Total estimated model params size (MB): 1.2 K
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/module.py:494: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing
`Trainer(logger=ALogger(...))`
Epoch 3/239 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 32/32 0:00:12 • 0:00:00 2.82it/s train_loss_step: 15.574 pixel_AUROC: 0.500 pixel_PRO: 0.007 train_loss_epoch: 15.4742024-06-25 15:55:38,221 - anomalib.callbacks.timer - INFO - Training took 117.79 seconds
[06/25/24 15:55:38] INFO     Training took 117.79 seconds                                                                                                                                                       timer.py:59
Epoch 3/239 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 32/32 0:00:12 • 0:00:00 2.82it/s train_loss_step: 15.574 pixel_AUROC: 0.500 pixel_PRO: 0.015 train_loss_epoch: 13.631
2024-06-25 15:55:38,225 - anomalib.data.image.btech - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                btech.py:351
2024-06-25 15:55:38,509 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/25/24 15:55:38] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14/14 0:00:56 • 0:00:00 0.23it/s  2024-06-25 15:56:44,393 - anomalib.callbacks.timer - INFO - Testing took 64.9417552947998 seconds
Throughput (batch_size=32) : 6.790700343686475 FPS
[06/25/24 15:56:44] INFO     Testing took 64.9417552947998 seconds                                                                                                                                             timer.py:109
                             Throughput (batch_size=32) : 6.790700343686475 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.29384148120880127    │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │     0.510677695274353     │
│         pixel_PRO         │   0.014986971393227577    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14/14 0:00:56 • 0:00:00 0.23it/s
