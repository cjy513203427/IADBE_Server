/bin/bash /home/jinyao/PycharmProjects/IADBE/train_test_mvtec_rkde.sh
(IADBE) jinyao@jinyao-System-Product-Name:~/PycharmProjects/IADBE$ /bin/bash /home/jinyao/PycharmProjects/IADBE/train_test_mvtec_rkde.sh
Running command: anomalib train --data anomalib.data.MVTec --data.category screw --config ./configs/models/rkde.yaml
2024-06-04 18:00:26,693 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:00:26] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:00:26,707 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:00:27,563 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:00:27] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:00:27,565 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:00:27,566 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:00:27,566 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:00:27,645 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:00:27] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:00:27,653 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:00:27,654 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:00:27,655 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:00:27,656 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:00:27,656 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:00:27,658 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:00:27,693 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:00:27,925 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10/10 0:00:08 • 0:00:00 1.56it/s  2024-06-04 18:00:36,516 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:00:36] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10/10 0:00:08 • 0:00:00 1.56it/s  2024-06-04 18:00:43,248 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:00:43] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10/10 0:00:08 • 0:00:00 1.56it/s  2024-06-04 18:00:43,557 - anomalib.callbacks.timer - INFO - Training took 15.62 seconds
[06/04/24 18:00:43] INFO     Training took 15.62 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10/10 0:00:08 • 0:00:00 1.56it/s
2024-06-04 18:00:43,562 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:00:43,910 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:15 • 0:00:00 0.26it/s  2024-06-04 18:01:04,648 - anomalib.callbacks.timer - INFO - Testing took 20.405717849731445 seconds
Throughput (batch_size=32) : 7.8409395434283 FPS
[06/04/24 18:01:04] INFO     Testing took 20.405717849731445 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 7.8409395434283 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5058413743972778     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:15 • 0:00:00 0.26it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category pill --config ./configs/models/rkde.yaml
2024-06-04 18:01:10,359 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:01:10] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:01:10,374 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:01:11,218 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:01:11] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:01:11,219 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:01:11,220 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:01:11,221 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:01:11,300 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:01:11] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:01:11,308 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:01:11,309 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:01:11,309 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:01:11,310 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:01:11,311 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:01:11,312 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:01:11,349 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:01:11,597 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:06 • 0:00:00 1.77it/s  2024-06-04 18:01:18,446 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:01:18] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:06 • 0:00:00 1.77it/s  2024-06-04 18:01:24,619 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:01:24] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:06 • 0:00:00 1.77it/s  2024-06-04 18:01:24,908 - anomalib.callbacks.timer - INFO - Training took 13.30 seconds
[06/04/24 18:01:24] INFO     Training took 13.30 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:06 • 0:00:00 1.77it/s
2024-06-04 18:01:24,913 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:01:25,138 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:01:25] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:18 • 0:00:00 0.28it/s  2024-06-04 18:01:45,594 - anomalib.callbacks.timer - INFO - Testing took 20.223729133605957 seconds
Throughput (batch_size=32) : 8.257626419773125 FPS
[06/04/24 18:01:45] INFO     Testing took 20.223729133605957 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 8.257626419773125 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.6876704692840576     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:18 • 0:00:00 0.28it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category capsule --config ./configs/models/rkde.yaml
2024-06-04 18:01:51,293 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:01:51] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:01:51,308 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:01:52,125 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:01:52] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:01:52,127 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:01:52,127 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:01:52,128 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:01:52,205 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:01:52] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:01:52,213 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:01:52,214 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:01:52,214 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:01:52,215 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:01:52,216 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:01:52,217 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:01:52,253 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:01:52,485 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.58it/s  2024-06-04 18:01:59,289 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:01:59] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.58it/s  2024-06-04 18:02:05,328 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:02:05] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.58it/s  2024-06-04 18:02:05,631 - anomalib.callbacks.timer - INFO - Training took 13.14 seconds
[06/04/24 18:02:05] INFO     Training took 13.14 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.58it/s
2024-06-04 18:02:05,635 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:02:05,923 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:17 • 0:00:00 0.24it/s  2024-06-04 18:02:25,475 - anomalib.callbacks.timer - INFO - Testing took 19.323993921279907 seconds
Throughput (batch_size=32) : 6.83088602375513 FPS
[06/04/24 18:02:25] INFO     Testing took 19.323993921279907 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 6.83088602375513 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5193458795547485     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:17 • 0:00:00 0.24it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category carpet --config ./configs/models/rkde.yaml
2024-06-04 18:02:31,226 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:02:31] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:02:31,241 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:02:32,100 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:02:32] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:02:32,102 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:02:32,103 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:02:32,103 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:02:32,182 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:02:32] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:02:32,191 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:02:32,191 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:02:32,192 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:02:32,193 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:02:32,193 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:02:32,195 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:02:32,234 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:02:32,471 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:07 • 0:00:00 1.68it/s  2024-06-04 18:02:40,429 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:02:40] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:07 • 0:00:00 1.68it/s  2024-06-04 18:02:40,433 - anomalib.models.components.classification.kde_classifier - INFO - Not enough features to commit. Not making a model.
                    INFO     Not enough features to commit. Not making a model.                                                                                                                        kde_classifier.py:92
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:07 • 0:00:00 1.68it/s
╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /home/jinyao/anaconda3/envs/IADBE/bin/anomalib:8 in <module>                                     │
│                                                                                                  │
│   5 from anomalib.cli.cli import main                                                            │
│   6 if __name__ == '__main__':                                                                   │
│   7 │   sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])                         │
│ ❱ 8 │   sys.exit(main())                                                                         │
│   9                                                                                              │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/cli/cli.py:486 in main   │
│                                                                                                  │
│   483 def main() -> None:                                                                        │
│   484 │   """Trainer via Anomalib CLI."""                                                        │
│   485 │   configure_logger()                                                                     │
│ ❱ 486 │   AnomalibCLI()                                                                          │
│   487                                                                                            │
│   488                                                                                            │
│   489 if __name__ == "__main__":                                                                 │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/cli/cli.py:65 in         │
│ __init__                                                                                         │
│                                                                                                  │
│    62 │   │   │   self.before_instantiate_classes()                                              │
│    63 │   │   │   self.instantiate_classes()                                                     │
│    64 │   │   if run:                                                                            │
│ ❱  65 │   │   │   self._run_subcommand()                                                         │
│    66 │                                                                                          │
│    67 │   def init_parser(self, **kwargs) -> ArgumentParser:                                     │
│    68 │   │   """Method that instantiates the argument parser."""                                │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/cli/cli.py:365 in        │
│ _run_subcommand                                                                                  │
│                                                                                                  │
│   362 │   │   elif self.config["subcommand"] in (*self.subcommands(), "train", "export", "pred   │
│   363 │   │   │   fn = getattr(self.engine, self.subcommand)                                     │
│   364 │   │   │   fn_kwargs = self._prepare_subcommand_kwargs(self.subcommand)                   │
│ ❱ 365 │   │   │   fn(**fn_kwargs)                                                                │
│   366 │   │   elif PIPELINE_REGISTRY is not None and self.subcommand in pipeline_subcommands()   │
│   367 │   │   │   run_pipeline(self.config)                                                      │
│   368 │   │   else:                                                                              │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/engine/engine.py:862 in  │
│ train                                                                                            │
│                                                                                                  │
│    859 │   │   │   # if the model is zero-shot or few-shot, we only need to run validate for no  │
│    860 │   │   │   self.trainer.validate(model, val_dataloaders, None, verbose=False, datamodul  │
│    861 │   │   else:                                                                             │
│ ❱  862 │   │   │   self.trainer.fit(model, train_dataloaders, val_dataloaders, datamodule, ckpt  │
│    863 │   │   self.trainer.test(model, test_dataloaders, ckpt_path=ckpt_path, datamodule=datam  │
│    864 │                                                                                         │
│    865 │   def export(                                                                           │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer │
│ .py:544 in fit                                                                                   │
│                                                                                                  │
│    541 │   │   self.state.fn = TrainerFn.FITTING                                                 │
│    542 │   │   self.state.status = TrainerStatus.RUNNING                                         │
│    543 │   │   self.training = True                                                              │
│ ❱  544 │   │   call._call_and_handle_interrupt(                                                  │
│    545 │   │   │   self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  │
│    546 │   │   )                                                                                 │
│    547                                                                                           │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py │
│ :44 in _call_and_handle_interrupt                                                                │
│                                                                                                  │
│    41 │   try:                                                                                   │
│    42 │   │   if trainer.strategy.launcher is not None:                                          │
│    43 │   │   │   return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    │
│ ❱  44 │   │   return trainer_fn(*args, **kwargs)                                                 │
│    45 │                                                                                          │
│    46 │   except _TunerExitException:                                                            │
│    47 │   │   _call_teardown_hook(trainer)                                                       │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer │
│ .py:580 in _fit_impl                                                                             │
│                                                                                                  │
│    577 │   │   │   model_provided=True,                                                          │
│    578 │   │   │   model_connected=self.lightning_module is not None,                            │
│    579 │   │   )                                                                                 │
│ ❱  580 │   │   self._run(model, ckpt_path=ckpt_path)                                             │
│    581 │   │                                                                                     │
│    582 │   │   assert self.state.stopped                                                         │
│    583 │   │   self.training = False                                                             │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer │
│ .py:989 in _run                                                                                  │
│                                                                                                  │
│    986 │   │   # ----------------------------                                                    │
│    987 │   │   # RUN THE TRAINER                                                                 │
│    988 │   │   # ----------------------------                                                    │
│ ❱  989 │   │   results = self._run_stage()                                                       │
│    990 │   │                                                                                     │
│    991 │   │   # ----------------------------                                                    │
│    992 │   │   # POST-Training CLEAN UP                                                          │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer │
│ .py:1035 in _run_stage                                                                           │
│                                                                                                  │
│   1032 │   │   │   with isolate_rng():                                                           │
│   1033 │   │   │   │   self._run_sanity_check()                                                  │
│   1034 │   │   │   with torch.autograd.set_detect_anomaly(self._detect_anomaly):                 │
│ ❱ 1035 │   │   │   │   self.fit_loop.run()                                                       │
│   1036 │   │   │   return None                                                                   │
│   1037 │   │   raise RuntimeError(f"Unexpected state {self.state}")                              │
│   1038                                                                                           │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop. │
│ py:202 in run                                                                                    │
│                                                                                                  │
│   199 │   │   while not self.done:                                                               │
│   200 │   │   │   try:                                                                           │
│   201 │   │   │   │   self.on_advance_start()                                                    │
│ ❱ 202 │   │   │   │   self.advance()                                                             │
│   203 │   │   │   │   self.on_advance_end()                                                      │
│   204 │   │   │   │   self._restarting = False                                                   │
│   205 │   │   │   except StopIteration:                                                          │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop. │
│ py:359 in advance                                                                                │
│                                                                                                  │
│   356 │   │   │   )                                                                              │
│   357 │   │   with self.trainer.profiler.profile("run_training_epoch"):                          │
│   358 │   │   │   assert self._data_fetcher is not None                                          │
│ ❱ 359 │   │   │   self.epoch_loop.run(self._data_fetcher)                                        │
│   360 │                                                                                          │
│   361 │   def on_advance_end(self) -> None:                                                      │
│   362 │   │   trainer = self.trainer                                                             │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/training_ │
│ epoch_loop.py:137 in run                                                                         │
│                                                                                                  │
│   134 │   │   while not self.done:                                                               │
│   135 │   │   │   try:                                                                           │
│   136 │   │   │   │   self.advance(data_fetcher)                                                 │
│ ❱ 137 │   │   │   │   self.on_advance_end(data_fetcher)                                          │
│   138 │   │   │   │   self._restarting = False                                                   │
│   139 │   │   │   except StopIteration:                                                          │
│   140 │   │   │   │   break                                                                      │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/training_ │
│ epoch_loop.py:285 in on_advance_end                                                              │
│                                                                                                  │
│   282 │   │   │   │   # clear gradients to not leave any unused memory during validation         │
│   283 │   │   │   │   call._call_lightning_module_hook(self.trainer, "on_validation_model_zero   │
│   284 │   │   │                                                                                  │
│ ❱ 285 │   │   │   self.val_loop.run()                                                            │
│   286 │   │   │   self.trainer.training = True                                                   │
│   287 │   │   │   self.trainer._logger_connector._first_loop_iter = first_loop_iter              │
│   288                                                                                            │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/utilities │
│ .py:182 in _decorator                                                                            │
│                                                                                                  │
│   179 │   │   else:                                                                              │
│   180 │   │   │   context_manager = torch.no_grad                                                │
│   181 │   │   with context_manager():                                                            │
│ ❱ 182 │   │   │   return loop_run(self, *args, **kwargs)                                         │
│   183 │                                                                                          │
│   184 │   return _decorator                                                                      │
│   185                                                                                            │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/evaluatio │
│ n_loop.py:134 in run                                                                             │
│                                                                                                  │
│   131 │   │   │   │   previous_dataloader_idx = dataloader_idx                                   │
│   132 │   │   │   │   self.batch_progress.is_last_batch = data_fetcher.done                      │
│   133 │   │   │   │   # run step hooks                                                           │
│ ❱ 134 │   │   │   │   self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)   │
│   135 │   │   │   except StopIteration:                                                          │
│   136 │   │   │   │   # this needs to wrap the `*_step` call too (not just `next`) for `datalo   │
│   137 │   │   │   │   break                                                                      │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/evaluatio │
│ n_loop.py:391 in _evaluation_step                                                                │
│                                                                                                  │
│   388 │   │   │   if not using_dataloader_iter                                                   │
│   389 │   │   │   else (dataloader_iter,)                                                        │
│   390 │   │   )                                                                                  │
│ ❱ 391 │   │   output = call._call_strategy_hook(trainer, hook_name, *step_args)                  │
│   392 │   │                                                                                      │
│   393 │   │   self.batch_progress.increment_processed()                                          │
│   394                                                                                            │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py │
│ :309 in _call_strategy_hook                                                                      │
│                                                                                                  │
│   306 │   │   return None                                                                        │
│   307 │                                                                                          │
│   308 │   with trainer.profiler.profile(f"[Strategy]{trainer.strategy.__class__.__name__}.{hoo   │
│ ❱ 309 │   │   output = fn(*args, **kwargs)                                                       │
│   310 │                                                                                          │
│   311 │   # restore current_fx when nested context                                               │
│   312 │   pl_module._current_fx_name = prev_fx_name                                              │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/strategies/stra │
│ tegy.py:403 in validation_step                                                                   │
│                                                                                                  │
│   400 │   │   with self.precision_plugin.val_step_context():                                     │
│   401 │   │   │   if self.model != self.lightning_module:                                        │
│   402 │   │   │   │   return self._forward_redirection(self.model, self.lightning_module, "val   │
│ ❱ 403 │   │   │   return self.lightning_module.validation_step(*args, **kwargs)                  │
│   404 │                                                                                          │
│   405 │   def test_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:                         │
│   406 │   │   """The actual test step.                                                           │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/models/image/rkde/lightn │
│ ing_model.py:119 in validation_step                                                              │
│                                                                                                  │
│   116 │   │   del args, kwargs  # These variables are not used.                                  │
│   117 │   │                                                                                      │
│   118 │   │   # get batched model predictions                                                    │
│ ❱ 119 │   │   boxes, scores = self.model(batch["image"])                                         │
│   120 │   │                                                                                      │
│   121 │   │   # convert batched predictions to list format                                       │
│   122 │   │   image: torch.Tensor = batch["image"]                                               │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/nn/modules/module.py:1518   │
│ in _wrapped_call_impl                                                                            │
│                                                                                                  │
│   1515 │   │   if self._compiled_call_impl is not None:                                          │
│   1516 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]        │
│   1517 │   │   else:                                                                             │
│ ❱ 1518 │   │   │   return self._call_impl(*args, **kwargs)                                       │
│   1519 │                                                                                         │
│   1520 │   def _call_impl(self, *args, **kwargs):                                                │
│   1521 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.fo  │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/nn/modules/module.py:1527   │
│ in _call_impl                                                                                    │
│                                                                                                  │
│   1524 │   │   if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks   │
│   1525 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hooks                   │
│   1526 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks):                   │
│ ❱ 1527 │   │   │   return forward_call(*args, **kwargs)                                          │
│   1528 │   │                                                                                     │
│   1529 │   │   try:                                                                              │
│   1530 │   │   │   result = None                                                                 │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/models/image/rkde/torch_ │
│ model.py:113 in forward                                                                          │
│                                                                                                  │
│   110 │   │   │   return features                                                                │
│   111 │   │                                                                                      │
│   112 │   │   # 3. apply density estimation                                                      │
│ ❱ 113 │   │   scores = self.classifier(features)                                                 │
│   114 │   │                                                                                      │
│   115 │   │   return rois, scores                                                                │
│   116                                                                                            │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/nn/modules/module.py:1518   │
│ in _wrapped_call_impl                                                                            │
│                                                                                                  │
│   1515 │   │   if self._compiled_call_impl is not None:                                          │
│   1516 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]        │
│   1517 │   │   else:                                                                             │
│ ❱ 1518 │   │   │   return self._call_impl(*args, **kwargs)                                       │
│   1519 │                                                                                         │
│   1520 │   def _call_impl(self, *args, **kwargs):                                                │
│   1521 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.fo  │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/nn/modules/module.py:1527   │
│ in _call_impl                                                                                    │
│                                                                                                  │
│   1524 │   │   if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks   │
│   1525 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hooks                   │
│   1526 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks):                   │
│ ❱ 1527 │   │   │   return forward_call(*args, **kwargs)                                          │
│   1528 │   │                                                                                     │
│   1529 │   │   try:                                                                              │
│   1530 │   │   │   result = None                                                                 │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/models/components/classi │
│ fication/kde_classifier.py:161 in forward                                                        │
│                                                                                                  │
│   158 │                                                                                          │
│   159 │   def forward(self, features: torch.Tensor) -> torch.Tensor:                             │
│   160 │   │   """Make predictions on extracted features."""                                      │
│ ❱ 161 │   │   return self.predict(features)                                                      │
│   162                                                                                            │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/models/components/classi │
│ fication/kde_classifier.py:156 in predict                                                        │
│                                                                                                  │
│   153 │   │   Returns:                                                                           │
│   154 │   │     Detection probabilities                                                          │
│   155 │   │   """                                                                                │
│ ❱ 156 │   │   scores = self.compute_kde_scores(features, as_log_likelihood=True)                 │
│   157 │   │   return self.compute_probabilities(scores)                                          │
│   158 │                                                                                          │
│   159 │   def forward(self, features: torch.Tensor) -> torch.Tensor:                             │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/models/components/classi │
│ fication/kde_classifier.py:122 in compute_kde_scores                                             │
│                                                                                                  │
│   119 │   │   Returns:                                                                           │
│   120 │   │   │   (torch.Tensor): Score                                                          │
│   121 │   │   """                                                                                │
│ ❱ 122 │   │   features = self.pca_model.transform(features)                                      │
│   123 │   │   features, _ = self.pre_process(features, self.max_length)                          │
│   124 │   │   # Scores are always assumed to be passed as a density                              │
│   125 │   │   kde_scores = self.kde_model(features)                                              │
│                                                                                                  │
│ /home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/anomalib/models/components/dimens │
│ ionality_reduction/pca.py:129 in transform                                                       │
│                                                                                                  │
│   126 │   │   │   >>> transformed_embedding.shape                                                │
│   127 │   │   │   torch.Size([1000, 2])                                                          │
│   128 │   │   """                                                                                │
│ ❱ 129 │   │   features -= self.mean                                                              │
│   130 │   │   return torch.matmul(features, self.singular_vectors)                               │
│   131 │                                                                                          │
│   132 │   def inverse_transform(self, features: torch.Tensor) -> torch.Tensor:                   │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
RuntimeError: The size of tensor a (4096) must match the size of tensor b (0) at non-singleton dimension 1
Running command: anomalib train --data anomalib.data.MVTec --data.category grid --config ./configs/models/rkde.yaml
2024-06-04 18:02:48,898 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:02:48] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:02:48,913 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:02:49,756 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:02:49] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:02:49,757 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:02:49,758 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:02:49,759 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:02:49,838 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:02:49] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:02:49,846 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:02:49,847 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:02:49,848 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:02:49,848 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:02:49,849 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:02:49,850 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:02:49,889 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:02:50,139 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:02:50] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:07 • 0:00:00 1.71it/s  2024-06-04 18:02:57,611 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:02:57] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:07 • 0:00:00 1.71it/s  2024-06-04 18:03:02,707 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:03:02] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:07 • 0:00:00 1.71it/s  2024-06-04 18:03:03,014 - anomalib.callbacks.timer - INFO - Training took 12.87 seconds
[06/04/24 18:03:03] INFO     Training took 12.87 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9/9 0:00:07 • 0:00:00 1.71it/s
2024-06-04 18:03:03,017 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:03:03,235 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:03:03] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:07 • 0:00:00 0.28it/s  2024-06-04 18:03:14,020 - anomalib.callbacks.timer - INFO - Testing took 10.565324306488037 seconds
Throughput (batch_size=32) : 7.3826413404178375 FPS
[06/04/24 18:03:14] INFO     Testing took 10.565324306488037 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 7.3826413404178375 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5822889804840088     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:07 • 0:00:00 0.28it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category tile --config ./configs/models/rkde.yaml
2024-06-04 18:03:19,672 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:03:19] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:03:19,687 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:03:20,528 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:03:20] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:03:20,530 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:03:20,530 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:03:20,531 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:03:20,612 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:03:20] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:03:20,620 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:03:20,621 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:03:20,622 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:03:20,622 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:03:20,623 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:03:20,624 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:03:20,666 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:03:20,906 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s  2024-06-04 18:03:27,538 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:03:27] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s  2024-06-04 18:04:05,901 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:04:05] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s  2024-06-04 18:04:06,201 - anomalib.callbacks.timer - INFO - Training took 45.29 seconds
[06/04/24 18:04:06] INFO     Training took 45.29 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s
2024-06-04 18:04:06,207 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:04:06,438 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:04:06] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:15 • 0:00:00 0.21it/s  2024-06-04 18:04:26,318 - anomalib.callbacks.timer - INFO - Testing took 19.588886499404907 seconds
Throughput (batch_size=32) : 5.972774409793755 FPS
[06/04/24 18:04:26] INFO     Testing took 19.588886499404907 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 5.972774409793755 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.7536075115203857     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:15 • 0:00:00 0.21it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category wood --config ./configs/models/rkde.yaml
2024-06-04 18:04:31,737 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:04:31] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:04:31,752 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:04:32,593 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:04:32] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:04:32,594 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:04:32,595 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:04:32,596 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:04:32,679 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:04:32] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:04:32,687 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:04:32,688 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:04:32,689 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:04:32,689 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:04:32,690 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:04:32,691 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:04:32,729 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:04:32,956 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.63it/s  2024-06-04 18:04:40,238 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:04:40] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.63it/s  2024-06-04 18:04:44,638 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:04:44] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.63it/s  2024-06-04 18:04:44,929 - anomalib.callbacks.timer - INFO - Training took 11.96 seconds
[06/04/24 18:04:44] INFO     Training took 11.96 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.63it/s
2024-06-04 18:04:44,933 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:04:45,161 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:04:45] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:09 • 0:00:00 0.24it/s  2024-06-04 18:04:58,121 - anomalib.callbacks.timer - INFO - Testing took 12.65358018875122 seconds
Throughput (batch_size=32) : 6.243292318977788 FPS
[06/04/24 18:04:58] INFO     Testing took 12.65358018875122 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 6.243292318977788 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.6771930456161499     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:09 • 0:00:00 0.24it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category zipper --config ./configs/models/rkde.yaml
2024-06-04 18:05:03,787 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:05:03] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:05:03,801 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:05:04,617 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:05:04] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:05:04,618 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:05:04,619 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:05:04,620 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:05:04,697 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:05:04] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:05:04,705 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:05:04,705 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:05:04,706 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:05:04,707 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:05:04,707 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:05:04,709 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:05:04,746 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:05:04,976 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s  2024-06-04 18:05:11,835 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:05:11] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s  2024-06-04 18:05:17,874 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:05:17] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s  2024-06-04 18:05:18,187 - anomalib.callbacks.timer - INFO - Training took 13.20 seconds
[06/04/24 18:05:18] INFO     Training took 13.20 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.73it/s
2024-06-04 18:05:18,190 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:05:18,476 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:05:18] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:15 • 0:00:00 0.28it/s  2024-06-04 18:05:37,636 - anomalib.callbacks.timer - INFO - Testing took 18.842021226882935 seconds
Throughput (batch_size=32) : 8.014002223103331 FPS
[06/04/24 18:05:37] INFO     Testing took 18.842021226882935 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 8.014002223103331 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.6253939867019653     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:15 • 0:00:00 0.28it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category cable --config ./configs/models/rkde.yaml
2024-06-04 18:05:43,225 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:05:43] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:05:43,240 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:05:44,085 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:05:44] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:05:44,094 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:05:44,095 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:05:44,096 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:05:44,175 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:05:44] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:05:44,184 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:05:44,184 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:05:44,185 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:05:44,186 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:05:44,187 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:05:44,188 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:05:44,225 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:05:44,466 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.63it/s  2024-06-04 18:05:51,224 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:05:51] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.63it/s  2024-06-04 18:05:58,249 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:05:58] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.63it/s  2024-06-04 18:05:58,561 - anomalib.callbacks.timer - INFO - Training took 14.09 seconds
[06/04/24 18:05:58] INFO     Training took 14.09 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.63it/s
2024-06-04 18:05:58,564 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:05:58,855 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:18 • 0:00:00 0.22it/s  2024-06-04 18:06:22,624 - anomalib.callbacks.timer - INFO - Testing took 23.435830116271973 seconds
Throughput (batch_size=32) : 6.400456022074164 FPS
[06/04/24 18:06:22] INFO     Testing took 23.435830116271973 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 6.400456022074164 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.7537481188774109     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:18 • 0:00:00 0.22it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category toothbrush --config ./configs/models/rkde.yaml
2024-06-04 18:06:28,465 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:06:28] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:06:28,480 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:06:29,310 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:06:29] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:06:29,311 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:06:29,312 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:06:29,313 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:06:29,392 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:06:29] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:06:29,400 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:06:29,401 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:06:29,402 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:06:29,402 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:06:29,403 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:06:29,404 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:06:29,442 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:06:29,670 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:02 • 0:00:00 1.70it/s  2024-06-04 18:06:33,002 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:06:33] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:02 • 0:00:00 1.70it/s  2024-06-04 18:06:36,690 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:06:36] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                 rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:02 • 0:00:00 1.70it/s  2024-06-04 18:06:36,984 - anomalib.callbacks.timer - INFO - Training took  7.31 seconds
[06/04/24 18:06:36] INFO     Training took  7.31 seconds                                                                                                                                                        timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:02 • 0:00:00 1.70it/s
2024-06-04 18:06:36,987 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:06:37,203 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:06:37] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:04 • 0:00:00 0.25it/s  2024-06-04 18:06:45,191 - anomalib.callbacks.timer - INFO - Testing took 7.700316429138184 seconds
Throughput (batch_size=32) : 5.454321310884184 FPS
[06/04/24 18:06:45] INFO     Testing took 7.700316429138184 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 5.454321310884184 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.8583333492279053     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:04 • 0:00:00 0.25it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category transistor --config ./configs/models/rkde.yaml
2024-06-04 18:06:50,712 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:06:50] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-06-04 18:06:50,727 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:06:51,584 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:06:51] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-06-04 18:06:51,586 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-06-04 18:06:51,586 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-06-04 18:06:51,587 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-06-04 18:06:51,667 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:06:51] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-06-04 18:06:51,675 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-06-04 18:06:51,676 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-06-04 18:06:51,677 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:06:51,677 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-06-04 18:06:51,678 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
2024-06-04 18:06:51,679 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-06-04 18:06:51,717 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:06:51,950 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.60it/s  2024-06-04 18:06:59,098 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:06:59] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                   lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.60it/s  2024-06-04 18:07:34,970 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:07:34] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                          rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.60it/s  2024-06-04 18:07:35,267 - anomalib.callbacks.timer - INFO - Training took 43.31 seconds
[06/04/24 18:07:35] INFO     Training took 43.31 seconds                                                                                                                                                                 timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:06 • 0:00:00 1.60it/s
2024-06-04 18:07:35,273 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:07:35,505 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:07:35] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:14 • 0:00:00 0.21it/s  2024-06-04 18:07:53,231 - anomalib.callbacks.timer - INFO - Testing took 17.409920930862427 seconds
Throughput (batch_size=32) : 5.743851473944996 FPS
[06/04/24 18:07:53] INFO     Testing took 17.409920930862427 seconds                                                                                                                                                    timer.py:109
                             Throughput (batch_size=32) : 5.743851473944996 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.7716666460037231     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:14 • 0:00:00 0.21it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category metal_nut --config ./configs/models/rkde.yaml
2024-06-04 18:07:58,788 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:07:58] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                             config.py:262
2024-06-04 18:07:58,803 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                           anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:07:59,643 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:07:59] INFO     Loading the callbacks                                                                                                                                                                    __init__.py:43
2024-06-04 18:07:59,644 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                                     engine.py:84
2024-06-04 18:07:59,645 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                            engine.py:84
2024-06-04 18:07:59,646 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                                  engine.py:84
2024-06-04 18:07:59,725 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:07:59] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary`         rank_zero.py:63
                             callback.
2024-06-04 18:07:59,734 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                                  rank_zero.py:63
2024-06-04 18:07:59,734 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                                rank_zero.py:63
2024-06-04 18:07:59,735 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:07:59,736 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:07:59,737 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please anomaly_module.py:235
                             override `configure_transforms` in your model.
2024-06-04 18:07:59,738 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:07:59,773 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which   rank_zero.py:63
                             will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:08:00,007 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:08:00] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(),
etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default,
which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call
to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.65it/s  2024-06-04 18:08:05,721 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:08:05] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                            lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.65it/s  2024-06-04 18:08:10,613 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:08:10] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                          rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.65it/s  2024-06-04 18:08:10,909 - anomalib.callbacks.timer - INFO - Training took 10.89 seconds
[06/04/24 18:08:10] INFO     Training took 10.89 seconds                                                                                                                                                                 timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.65it/s
2024-06-04 18:08:10,914 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:08:11,139 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:08:11] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:11 • 0:00:00 0.28it/s  2024-06-04 18:08:25,141 - anomalib.callbacks.timer - INFO - Testing took 13.775549173355103 seconds
Throughput (batch_size=32) : 8.348124532300673 FPS
[06/04/24 18:08:25] INFO     Testing took 13.775549173355103 seconds                                                                                                                                                    timer.py:109
                             Throughput (batch_size=32) : 8.348124532300673 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.6500488519668579     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:11 • 0:00:00 0.28it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category bottle --config ./configs/models/rkde.yaml
2024-06-04 18:08:30,923 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:08:30] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                             config.py:262
2024-06-04 18:08:30,937 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                           anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:08:31,772 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:08:31] INFO     Loading the callbacks                                                                                                                                                                    __init__.py:43
2024-06-04 18:08:31,774 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                                     engine.py:84
2024-06-04 18:08:31,775 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                            engine.py:84
2024-06-04 18:08:31,775 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                                  engine.py:84
2024-06-04 18:08:31,855 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:08:31] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary`         rank_zero.py:63
                             callback.
2024-06-04 18:08:31,863 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                                  rank_zero.py:63
2024-06-04 18:08:31,863 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                                rank_zero.py:63
2024-06-04 18:08:31,864 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:08:31,865 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:08:31,866 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please anomaly_module.py:235
                             override `configure_transforms` in your model.
2024-06-04 18:08:31,867 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:08:31,905 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which   rank_zero.py:63
                             will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:08:32,135 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:08:32] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(),
etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default,
which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call
to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.76it/s  2024-06-04 18:08:38,127 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:08:38] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                            lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.76it/s  2024-06-04 18:08:42,332 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:08:42] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                          rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.76it/s  2024-06-04 18:08:42,630 - anomalib.callbacks.timer - INFO - Training took 10.49 seconds
[06/04/24 18:08:42] INFO     Training took 10.49 seconds                                                                                                                                                                 timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/7 0:00:05 • 0:00:00 1.76it/s
2024-06-04 18:08:42,635 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:08:42,934 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:07 • 0:00:00 0.27it/s  2024-06-04 18:08:54,463 - anomalib.callbacks.timer - INFO - Testing took 11.21090030670166 seconds
Throughput (batch_size=32) : 7.403508882367298 FPS
[06/04/24 18:08:54] INFO     Testing took 11.21090030670166 seconds                                                                                                                                                     timer.py:109
                             Throughput (batch_size=32) : 7.403508882367298 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.9063491821289062     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:07 • 0:00:00 0.27it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category hazelnut --config ./configs/models/rkde.yaml
2024-06-04 18:09:00,117 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:09:00] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                             config.py:262
2024-06-04 18:09:00,132 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                           anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:09:00,969 - anomalib.callbacks - INFO - Loading the callbacks
                    INFO     Loading the callbacks                                                                                                                                                                    __init__.py:43
2024-06-04 18:09:00,971 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                                     engine.py:84
2024-06-04 18:09:00,971 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                            engine.py:84
2024-06-04 18:09:00,972 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                                  engine.py:84
2024-06-04 18:09:01,054 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:09:01] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary`         rank_zero.py:63
                             callback.
2024-06-04 18:09:01,062 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                                  rank_zero.py:63
2024-06-04 18:09:01,063 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                                rank_zero.py:63
2024-06-04 18:09:01,063 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:09:01,064 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:09:01,065 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
[06/04/24 18:09:01] WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please anomaly_module.py:235
                             override `configure_transforms` in your model.
2024-06-04 18:09:01,066 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:09:01,105 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which   rank_zero.py:63
                             will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:09:01,349 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(),
etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default,
which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call
to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:09 • 0:00:00 1.73it/s  2024-06-04 18:09:11,611 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:09:11] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                            lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:09 • 0:00:00 1.73it/s  2024-06-04 18:09:17,208 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:09:17] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                          rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:09 • 0:00:00 1.73it/s  2024-06-04 18:09:17,487 - anomalib.callbacks.timer - INFO - Training took 16.13 seconds
[06/04/24 18:09:17] INFO     Training took 16.13 seconds                                                                                                                                                                 timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:09 • 0:00:00 1.73it/s
2024-06-04 18:09:17,491 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:09:17,711 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:13 • 0:00:00 0.24it/s  2024-06-04 18:09:34,747 - anomalib.callbacks.timer - INFO - Testing took 16.69364857673645 seconds
Throughput (batch_size=32) : 6.5893324334915775 FPS
[06/04/24 18:09:34] INFO     Testing took 16.69364857673645 seconds                                                                                                                                                     timer.py:109
                             Throughput (batch_size=32) : 6.5893324334915775 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.8507142066955566     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:13 • 0:00:00 0.24it/s
Running command: anomalib train --data anomalib.data.MVTec --data.category leather --config ./configs/models/rkde.yaml
2024-06-04 18:09:40,600 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[06/04/24 18:09:40] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                             config.py:262
2024-06-04 18:09:40,615 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                           anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-06-04 18:09:41,452 - anomalib.callbacks - INFO - Loading the callbacks
[06/04/24 18:09:41] INFO     Loading the callbacks                                                                                                                                                                    __init__.py:43
2024-06-04 18:09:41,453 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                                     engine.py:84
2024-06-04 18:09:41,454 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                            engine.py:84
2024-06-04 18:09:41,455 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                                  engine.py:84
2024-06-04 18:09:41,535 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[06/04/24 18:09:41] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary`         rank_zero.py:63
                             callback.
2024-06-04 18:09:41,543 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                                  rank_zero.py:63
2024-06-04 18:09:41,544 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                                rank_zero.py:63
2024-06-04 18:09:41,545 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:09:41,545 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                                     rank_zero.py:63
2024-06-04 18:09:41,546 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
                    WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please anomaly_module.py:235
                             override `configure_transforms` in your model.
2024-06-04 18:09:41,548 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:09:41,585 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which   rank_zero.py:63
                             will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-06-04 18:09:41,833 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ RkdeModel                │ 98.8 M │
│ 1 │ _transform            │ Compose                  │      0 │
│ 2 │ normalization_metrics │ MinMax                   │      0 │
│ 3 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 4 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 6 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 98.5 M
Non-trainable params: 222 K
Total params: 98.8 M
Total estimated model params size (MB): 395
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(),
etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default,
which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call
to weights.transforms(antialias=True).
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.69it/s  2024-06-04 18:09:48,911 - anomalib.models.image.rkde.lightning_model - INFO - Fitting a KDE model to the embedding collected from the training set.
[06/04/24 18:09:48] INFO     Fitting a KDE model to the embedding collected from the training set.                                                                                                            lightning_model.py:100
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.69it/s  2024-06-04 18:09:54,695 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[06/04/24 18:09:54] INFO     `Trainer.fit` stopped: `max_epochs=1` reached.                                                                                                                                          rank_zero.py:63
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.69it/s  2024-06-04 18:09:55,012 - anomalib.callbacks.timer - INFO - Training took 13.17 seconds
[06/04/24 18:09:55] INFO     Training took 13.17 seconds                                                                                                                                                                 timer.py:59
Epoch 0/0  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:06 • 0:00:00 1.69it/s
2024-06-04 18:09:55,015 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                         mvtec.py:412
2024-06-04 18:09:55,322 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[06/04/24 18:09:55] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                                    cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:13 • 0:00:00 0.23it/s  2024-06-04 18:10:13,901 - anomalib.callbacks.timer - INFO - Testing took 18.363892555236816 seconds
Throughput (batch_size=32) : 6.752381044869434 FPS
[06/04/24 18:10:13] INFO     Testing took 18.363892555236816 seconds                                                                                                                                                    timer.py:109
                             Throughput (batch_size=32) : 6.752381044869434 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5096806883811951     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:13 • 0:00:00 0.23it/s

