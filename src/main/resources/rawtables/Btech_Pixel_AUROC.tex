\begin{table}[h!]
    \centering
    \captionsetup{justification=raggedright}
        \begin{tabular}{l*{4}{c}}
        \toprule
         & 01 & 02 & 03 & Average \\
        \midrule
        CFA & 51.57 & \textbf{95.50} & \textbf{99.52} & 82.20 \\
        CFLOW & \textbf{95.06} & 94.21 & \textbf{99.64} & \textbf{96.30} \\
        CSFLOW & 47.61 & 68.91 & 51.07 & 55.86 \\
        DFKDE & - & - & - & - \\
        DFM & 93.15 & 94.50 & \textbf{99.34} & \textbf{95.66} \\
        DRAEM & - & - & - & - \\
        DSR & 75.69 & 67.20 & 55.29 & 66.06 \\
        FASTFLOW & \textbf{95.44} & \textbf{95.90} & \textbf{98.86} & \textbf{96.73} \\
        FRE & \textbf{95.74} & \textbf{95.00} & \textbf{98.78} & \textbf{96.51} \\
        GANomaly & 51.80 & 60.33 & 44.39 & 52.17 \\
        PaDiM & \textbf{97.13} & \textbf{95.68} & \textbf{99.61} & \textbf{97.47} \\
        PatchCore & \textbf{96.56} & \textbf{95.39} & \textbf{99.46} & \textbf{97.14} \\
        RD & \textbf{97.39} & \textbf{96.76} & \textbf{99.72} & \textbf{97.96} \\
        RKDE & - & - & - & - \\
        STFPM & 94.81 & \textbf{97.21} & \textbf{99.09} & \textbf{97.04} \\
        UFLOW & \textbf{95.49} & \textbf{96.28} & \textbf{99.47} & \textbf{97.08} \\
        \bottomrule
        \end{tabular}
    \caption{Pixel Level AUROC Scores for Btech\cite{Bergmann_2022_mvtec3d} dataset categories - The table presents the Per-Region Overlap (PRO) scores for 15 different methods across 3 different categories from the Btech dataset. Higher PRO scores indicate superior performance in distinguishing between normal and anomalous images.}
    \label{table:Btech Pixel AUROC}
\end{table}